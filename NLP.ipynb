{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('News.txt') as f:\n",
    "    lines = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budapest\n",
      "Budapest\n",
      "Fukuoka\n",
      "Official Domain\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(lines)\n",
    "\n",
    "for ent in doc1.ents:\n",
    "    if ent.label_ == \"GPE\" :\n",
    "        print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McKeown lowers own mark for second world record in two days - CNA\n",
      "Kaylee McKeown set her second world record in two days on Saturday as the Australian lowered her own mark to win the 100 metres backstroke at the World Aquatics Swimming World Cup in Budapest.McKeown shaved 0.12 seconds off her previous best time to finish in 57.33, less than 24 hours after setting a world record in the 50 metres backstroke.\"Crazy scenes here in Budapest and surprised with my results to say the least,\" McKeown wrote on Instagram.\"It's been an absolute beauty of a year and what better way to top it off (than) with two world records.\"Excited and nervous for this coming season.\"In addition to setting two world records this weekend, the 22-year-old won the 50, 100 and 200 titles at the world championships in Fukuoka in July.McKeown, the reigning Olympic champion in the 100 and 200 backstroke, holds the world record in all three distances in the discipline, having set the 200 mark in March at the New South Wales state championships.\n",
      "\n",
      "Official Domain\n",
      "|\n",
      "Terms & Conditions\n",
      "|\n",
      "Privacy Policy\n",
      "This browser is no longer supported\n",
      "We know it's a hassle to switch browsers but we want your experience with CNA to be fast, secure and the best it can possibly be.\n",
      "To continue, upgrade to a supported browser or, for the finest experience, download the mobile app.\n",
      "Upgraded but still having issues? Contact us\n",
      " <-> Economics 0.21892309468525392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sures\\AppData\\Local\\Temp\\ipykernel_17276\\2045662332.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"Economics\")\n",
    "\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine whether a risk and classify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built a multilabel classification system using SpaCy (build and train the modek)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(train_data):\n",
    "\n",
    "    train_data = train_data.drop(columns=[\"Id\"])\n",
    "\n",
    "    data = tuple(zip(train_data['Title'].tolist(), train_data['Label'].tolist())) \n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        if (label=='Nature'):\n",
    "            doc.cats['Nature'] = 1\n",
    "            doc.cats['Politics'] = 0\n",
    "            doc.cats['Entertainment']  = 0\n",
    "            doc.cats['Economics']  = 0\n",
    "            doc.cats['Culture']  = 0\n",
    "            doc.cats['Science']  = 0\n",
    "        elif (label=='Politics'):\n",
    "            doc.cats['Nature'] = 0\n",
    "            doc.cats['Politics'] = 1\n",
    "            doc.cats['Entertainment']  = 0\n",
    "            doc.cats['Economics']  = 0\n",
    "            doc.cats['Culture']  = 0\n",
    "            doc.cats['Science']  = 0\n",
    "        elif (label=='Entertainment'):\n",
    "            doc.cats['Nature'] = 0\n",
    "            doc.cats['Politics'] = 0\n",
    "            doc.cats['Entertainment']  = 1\n",
    "            doc.cats['Economics']  = 0\n",
    "            doc.cats['Culture']  = 0\n",
    "            doc.cats['Science']  = 0\n",
    "        elif (label=='Economics'):\n",
    "            doc.cats['Nature'] = 0\n",
    "            doc.cats['Politics'] = 0\n",
    "            doc.cats['Entertainment']  = 0\n",
    "            doc.cats['Economics']  = 1\n",
    "            doc.cats['Culture']  = 0\n",
    "            doc.cats['Science']  = 0\n",
    "        elif (label=='Culture'):\n",
    "            doc.cats['Nature'] = 0\n",
    "            doc.cats['Politics'] = 0\n",
    "            doc.cats['Entertainment']  = 0\n",
    "            doc.cats['Economics']  = 0\n",
    "            doc.cats['Culture']  = 1\n",
    "            doc.cats['Science']  = 0\n",
    "        elif (label=='Science'):\n",
    "            doc.cats['Nature'] = 0\n",
    "            doc.cats['Politics'] = 0\n",
    "            doc.cats['Entertainment']  = 0\n",
    "            doc.cats['Economics']  = 0\n",
    "            doc.cats['Culture']  = 0\n",
    "            doc.cats['Science']  = 1        \n",
    "\n",
    "        docs.append(doc)\n",
    "\n",
    "    return docs,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 372.32it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 512.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\Work\\Programming\\Hackathons\\Diplomacy software\\Dimensions.csv\")\n",
    "train = df.sample(frac=0.7, replace=False, random_state=1)\n",
    "\n",
    "train_docs, train_data = make_docs(train)\n",
    "\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"./textcat_data/textcat_train.spacy\")\n",
    "\n",
    "test = df.sample(frac=0.3, replace=False, random_state=1)\n",
    "\n",
    "test_docs, train_data = make_docs(test)\n",
    "\n",
    "doc_bin = DocBin(docs=test_docs)\n",
    "doc_bin.to_disk(\"./textcat_data/textcat_valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBA Playoffs: Lakers and Clippers Face Off in ...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Exotic Destinations for Your Next Adventure Va...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>President Signs Historic Climate Change Legisl...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Scientific Expedition Discovers New Species in...</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>High School Robotics Team Wins International C...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mental Health Awareness Month: Initiatives to ...</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Innovative Schools Implement Technology-Driven...</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wildfires Threaten Communities in the Western ...</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Researchers Develop Promising Treatment for Al...</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Education Policy Reforms Aim to Improve Studen...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Discovering the Hidden Gems of a Charming Euro...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Breakthrough in Quantum Computing Paves the Wa...</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title          Label\n",
       "2   NBA Playoffs: Lakers and Clippers Face Off in ...  Entertainment\n",
       "30  Exotic Destinations for Your Next Adventure Va...  Entertainment\n",
       "3   President Signs Historic Climate Change Legisl...       Politics\n",
       "21  Scientific Expedition Discovers New Species in...        Science\n",
       "26  High School Robotics Team Wins International C...       Politics\n",
       "28  Mental Health Awareness Month: Initiatives to ...        Science\n",
       "22  Innovative Schools Implement Technology-Driven...        Science\n",
       "36  Wildfires Threaten Communities in the Western ...         Nature\n",
       "19  Researchers Develop Promising Treatment for Al...        Science\n",
       "25  Education Policy Reforms Aim to Improve Studen...       Politics\n",
       "31  Discovering the Hidden Gems of a Charming Euro...  Entertainment\n",
       "17  Breakthrough in Quantum Computing Paves the Wa...        Science"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "textcat_config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train textcat_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./textcat_base_config.cfg ./textcat_config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-27 22:02:30,992] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "[2023-10-27 22:02:31,180] [INFO] Set up nlp object from config\n",
      "[2023-10-27 22:02:31,187] [DEBUG] Loading corpus from path: textcat_data\\textcat_valid.spacy\n",
      "[2023-10-27 22:02:31,192] [DEBUG] Loading corpus from path: textcat_data\\textcat_train.spacy\n",
      "[2023-10-27 22:02:31,192] [INFO] Pipeline: ['tok2vec', 'textcat']\n",
      "[2023-10-27 22:02:31,192] [INFO] Created vocabulary\n",
      "[2023-10-27 22:02:31,587] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
      "[2023-10-27 22:02:31,587] [INFO] Added vectors: en_core_web_sm\n",
      "[2023-10-27 22:02:31,587] [INFO] Finished initializing nlp object\n",
      "[2023-10-27 22:02:31,852] [INFO] Initialized pipeline components: ['tok2vec', 'textcat']\n",
      "[2023-10-27 22:02:31,864] [DEBUG] Loading corpus from path: textcat_data\\textcat_valid.spacy\n",
      "[2023-10-27 22:02:31,864] [DEBUG] Loading corpus from path: textcat_data\\textcat_train.spacy\n",
      "[2023-10-27 22:02:31,872] [DEBUG] Removed existing output directory: textcat_output\\model-best\n",
      "[2023-10-27 22:02:31,882] [DEBUG] Removed existing output directory: textcat_output\\model-last\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: textcat_output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ------------  ----------  ------\n",
      "  0       0          0.00          0.14       37.26    0.37\n",
      " 77     200         84.36          1.09       66.67    0.67\n",
      "177     400        482.64          0.23       66.67    0.67\n",
      "277     600         19.61          0.01       66.67    0.67\n",
      "418     800          0.00          0.00       66.67    0.67\n",
      "618    1000          0.00          0.00       66.67    0.67\n",
      "818    1200          0.00          0.00       66.67    0.67\n",
      "1018    1400          0.00          0.00       66.67    0.67\n",
      "1218    1600          0.00          0.00       66.67    0.67\n",
      "1418    1800          0.00          0.00       66.67    0.67\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "textcat_output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train textcat_config.cfg --verbose --output ./textcat_output --paths.train textcat_data/textcat_train.spacy --paths.dev textcat_data/textcat_valid.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nature': 0.6959365010261536, 'Politics': 2.370913716731593e-05, 'Entertainment': 2.5340261000650344e-09, 'Economics': 0.1244477927684784, 'Culture': 0.00027904147282242775, 'Science': 0.17931297421455383}\n",
      "Singapore votes in favour of UN resolution to protect civilians, uphold humanitarian obligations in Gaza Strip\n",
      "The class of this headline is Nature\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Enter a headline to analyse: \")\n",
    "nlp_textcat = spacy.load(os.getcwd() + \"\\\\textcat_output\\\\model-last\")\n",
    "docPred = nlp_textcat(prompt)\n",
    "res = docPred.cats\n",
    "print(res)\n",
    "print(prompt)\n",
    "print(\"The class of this headline is\", max(res, key=res.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
